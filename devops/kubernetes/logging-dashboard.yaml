---
# Grafana Dashboard ConfigMap for Logging
apiVersion: v1
kind: ConfigMap
metadata:
  name: logging-dashboard
  namespace: logging
  labels:
    app.kubernetes.io/name: grafana-dashboard
    grafana_dashboard: "1"
data:
  social-media-logging.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Social Media Platform - Logging Dashboard",
        "tags": ["social-media", "logging", "backend"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Log Volume by Level",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(rate(fluentbit_input_records_total[5m])) by (level)",
                "legendFormat": "{{level}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "displayMode": "basic"
                },
                "unit": "reqps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Error Rate",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(rate(fluentbit_input_records_total{level=\"error\"}[5m]))",
                "legendFormat": "Errors/sec"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1},
                    {"color": "red", "value": 5}
                  ]
                },
                "unit": "reqps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "WebSocket Events",
            "type": "timeseries",
            "targets": [
              {
                "expr": "sum(rate(vector_events_processed_total{websocket_event!=\"\"}[5m])) by (websocket_event)",
                "legendFormat": "{{websocket_event}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "linear",
                  "pointSize": 5,
                  "showPoints": "never"
                },
                "unit": "reqps"
              }
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Response Times",
            "type": "timeseries",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(vector_duration_ms_bucket[5m])) by (le))",
                "legendFormat": "95th percentile"
              },
              {
                "expr": "histogram_quantile(0.50, sum(rate(vector_duration_ms_bucket[5m])) by (le))",
                "legendFormat": "50th percentile"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "unit": "ms"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16}
          },
          {
            "id": 5,
            "title": "Active Rooms",
            "type": "stat",
            "targets": [
              {
                "expr": "count(count by (room_id)(vector_events_processed_total{room_id!=\"\"}))",
                "legendFormat": "Active Rooms"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "unit": "short"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16}
          },
          {
            "id": 6,
            "title": "Log Processing Pipeline Health",
            "type": "table",
            "targets": [
              {
                "expr": "up{job=~\"fluent-bit|vector|elasticsearch\"}",
                "format": "table",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "displayMode": "color-background"
                },
                "mappings": [
                  {
                    "options": {
                      "0": {"color": "red", "text": "Down"},
                      "1": {"color": "green", "text": "Up"}
                    },
                    "type": "value"
                  }
                ]
              }
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24}
          }
        ]
      }
    }
---
# Alerting Rules ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: logging-alerts-config
  namespace: logging
  labels:
    app.kubernetes.io/name: logging-alerts
data:
  alerts.yml: |
    groups:
    - name: social-media-logging
      rules:
      - alert: HighErrorRate
        expr: rate(fluentbit_input_records_total{level="error"}[5m]) > 5
        for: 2m
        labels:
          severity: warning
          service: backend
        annotations:
          summary: "High error rate in backend logs"
          description: "Error rate is {{ $value }} errors per second for {{ $labels.pod_name }}"
          runbook_url: "https://docs.social-media.com/runbooks/high-error-rate"
      
      - alert: LogProcessingDelay
        expr: time() - vector_last_event_timestamp > 300
        for: 5m
        labels:
          severity: warning
          service: logging
        annotations:
          summary: "Log processing delay detected"
          description: "Last log event was processed {{ $value }} seconds ago"
      
      - alert: ElasticsearchDiskUsage
        expr: elasticsearch_filesystem_data_available_bytes / elasticsearch_filesystem_data_size_bytes < 0.1
        for: 5m
        labels:
          severity: critical
          service: elasticsearch
        annotations:
          summary: "Elasticsearch disk usage is high"
          description: "Available disk space is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
      
      - alert: KibanaDown
        expr: up{job="kibana"} == 0
        for: 1m
        labels:
          severity: warning
          service: kibana
        annotations:
          summary: "Kibana is down"
          description: "Kibana dashboard is not accessible"
